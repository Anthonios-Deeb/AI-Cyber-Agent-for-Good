# CyberAgent: Detecting Botnet Activity Using Fine-Tuned LLaMA 2

This project presents a hybrid approach to detecting botnet activity in network traffic using a combination of traditional machine learning and a fine-tuned large language model (LLM). The solution leverages the CTU-13 dataset and applies both Random Forest and a LoRA fine-tuned LLaMA 2 7B chat model for classification and explanation of network flows.

---

## ğŸš€ Project Overview

The goal is to build an intelligent agent capable of:

- Classifying network flows as **normal** or **botnet activity**
- Generating **natural language explanations** for each classification
- Providing a **command-line interface** (UI) for manual or batch evaluation
- Supporting **real-time demonstration** and model evaluation

---

## ğŸ“‚ Repository Structure

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Filtered/            # Filtered CTU-13 flows (CSV)
â”‚   â””â”€â”€ FineTuning/          # Training data for LLaMA2 (JSONL)
â”œâ”€â”€ models/                  # Saved fine-tuned model checkpoints
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ build_training_prompts.py  # Generates instruction-output training pairs
â”‚   â”œâ”€â”€ train.py                   # Fine-tunes LLaMA2 with LoRA
â”‚   â”œâ”€â”€ predict.py                 # CLI-based real-time inference tool
â”‚   â””â”€â”€ evaluate_models.py        # Compares baseline and SOTA performance
â””â”€â”€ README.md
```

---

## ğŸ“Š Dataset

- **Source**: [CTU-13 Botnet Dataset](https://www.stratosphereips.org/datasets-ctu13)
- Labeled flows: `From-Botnet` vs. `From-Normal`
- Used to train both classic ML models and generate prompts for LLaMA2

---

## ğŸ§  Models

### ğŸ”¹ Baseline: Random Forest
- Trained on numerical features from the CTU-13 flows
- Fast and interpretable, but lacks contextual understanding

### ğŸ”¸ SOTA: LLaMA 2 7B + LoRA
- Fine-tuned on flow metadata â†’ instruction/output format
- Supports 4-bit quantization (nf4)
- Generates classification + reasoning text per flow

---

## ğŸ› ï¸ Installation

### âœ… Prerequisites

- Python 3.10+
- Git, pip
- GPU recommended (for training/inference)

### ğŸ”§ 1. Clone the Project

```bash
git clone https://github.com/Anthonios-Deeb/AI-Cyber-Agent-for-Good
cd cyberagent-llama2
```

### ğŸ“¦ 2. Setup Environment

```bash
python -m venv venv
source venv/bin/activate     # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

---

## ğŸ§ª Training the LLM Agent

To fine-tune the LLaMA 2 model with LoRA:

```bash
python scripts/fine_tune_llama.py
```

- Model checkpoints saved to: `models/llama2-finetuned-cyberagent`

---

## ğŸ“ˆ Evaluating Models

To compare Random Forest (baseline) vs. fine-tuned LLaMA:

```bash
python scripts/evaluate_models.py
```

- Evaluates both models on the same test set
- Metrics: accuracy, precision, recall, F1

---

## ğŸ’¡ Real-Time Inference (Terminal UI)

Run the real-time CLI predictor:

```bash
python scripts/predict.py
```

Options:
- `1`: Enter flows manually
- `2`: Auto-sample random flows from CTU-13 and predict

---

## ğŸ“¸ Live Demo

- Terminal screenshots included in presentation
- Examples shown for both `normal` and `botnet` responses with LLM explanations

---

## âš™ï¸ LoRA Fine-Tuning Config

| Param         | Value       |
|---------------|-------------|
| `r`           | 16          |
| `alpha`       | 32          |
| Target modules| `q_proj`, `v_proj` |
| `dropout`     | 0.05        |
| Optimizer     | `paged_adamw_8bit` |
| Steps         | 500         |
| Precision     | `fp16`      |

---

## ğŸ“Š Baseline vs. SOTA Summary

| Model           | Pros                                 | Cons                                     |
|-----------------|---------------------------------------|------------------------------------------|
| Random Forest   | Fast, easy to interpret              | No explanation, relies on fixed features |
| LLaMA 2 + LoRA  | Explanations, adaptable, generalizes | Slower, needs GPU                        |

---

## ğŸ”— Useful Links

- [CTU-13 Dataset](https://www.stratosphereips.org/datasets-ctu13)
- [LLaMA 2 HF](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf)
